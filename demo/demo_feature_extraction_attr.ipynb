{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tqdm\n",
    "import detectron2\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Show the image in ipynb\n",
    "from IPython.display import clear_output, Image, display\n",
    "import PIL.Image\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VG Classes\n",
    "data_path = '/scratch/gobi1/johnchen/new_git_stuff/py-bottom-up-attention/data'\n",
    "\n",
    "vg_classes = []\n",
    "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        vg_classes.append(object.split(',')[0].lower().strip())\n",
    "        \n",
    "vg_attrs = []\n",
    "with open(os.path.join(data_path, 'attributes_vocab.txt')) as f:\n",
    "    for object in f.readlines():\n",
    "        vg_attrs.append(object.split(',')[0].lower().strip())\n",
    "\n",
    "\n",
    "MetadataCatalog.get(\"vg\").thing_classes = vg_classes\n",
    "MetadataCatalog.get(\"vg\").attr_classes = vg_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config '../configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modifications for VG in ResNet Backbone (modeling/backbone/resnet.py):\n",
      "\tUsing pad 0 in stem max_pool instead of pad 1.\n",
      "\n",
      "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
      "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
      "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
      "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
      "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
      "\n",
      "Modifications for VG in RoI heads (modeling/roi_heads/fast_rcnn.py))\n",
      "\tEmbedding: 1601 --> 256\tLinear: 2304 --> 512\tLinear: 512 --> 401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/VG-Detection/faster_rcnn_R_101_C4_attr_caffemaxpool.yaml\")\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 300\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.6\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n",
    "# VG Weight\n",
    "cfg.MODEL.WEIGHTS = \"http://nlp.cs.unc.edu/models/faster_rcnn_from_caffe_attr.pkl\"\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_OBJECTS = 36\n",
    "\n",
    "from detectron2.modeling.postprocessing import detector_postprocess\n",
    "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers, FastRCNNOutputs, fast_rcnn_inference_single_image\n",
    "\n",
    "def doit(raw_image):\n",
    "    with torch.no_grad():\n",
    "        raw_height, raw_width = raw_image.shape[:2]\n",
    "        print(\"Original image size: \", (raw_height, raw_width))\n",
    "        \n",
    "        # Preprocessing\n",
    "        image = predictor.transform_gen.get_transform(raw_image).apply_image(raw_image)\n",
    "        print(\"Transformed image size: \", image.shape[:2])\n",
    "        image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "        inputs = [{\"image\": image, \"height\": raw_height, \"width\": raw_width}]\n",
    "        images = predictor.model.preprocess_image(inputs)\n",
    "        \n",
    "        # Run Backbone Res1-Res4\n",
    "        features = predictor.model.backbone(images.tensor)\n",
    "        \n",
    "        # Generate proposals with RPN\n",
    "        proposals, _ = predictor.model.proposal_generator(images, features, None)\n",
    "        proposal = proposals[0]\n",
    "        print('Proposal Boxes size:', proposal.proposal_boxes.tensor.shape)\n",
    "        \n",
    "        # Run RoI head for each proposal (RoI Pooling + Res5)\n",
    "        proposal_boxes = [x.proposal_boxes for x in proposals]\n",
    "        features = [features[f] for f in predictor.model.roi_heads.in_features]\n",
    "        box_features = predictor.model.roi_heads._shared_roi_transform(\n",
    "            features, proposal_boxes\n",
    "        )\n",
    "        feature_pooled = box_features.mean(dim=[2, 3])  # pooled to 1x1\n",
    "        print('Pooled features size:', feature_pooled.shape)\n",
    "        \n",
    "        # Predict classes and boxes for each proposal.\n",
    "        pred_class_logits, pred_attr_logits, pred_proposal_deltas = predictor.model.roi_heads.box_predictor(feature_pooled)\n",
    "        outputs = FastRCNNOutputs(\n",
    "            predictor.model.roi_heads.box2box_transform,\n",
    "            pred_class_logits,\n",
    "            pred_proposal_deltas,\n",
    "            proposals,\n",
    "            predictor.model.roi_heads.smooth_l1_beta,\n",
    "        )\n",
    "        probs = outputs.predict_probs()[0]\n",
    "        boxes = outputs.predict_boxes()[0]\n",
    "        \n",
    "        attr_prob = pred_attr_logits[..., :-1].softmax(-1)\n",
    "        max_attr_prob, max_attr_label = attr_prob.max(-1)\n",
    "        \n",
    "        # Note: BUTD uses raw RoI predictions,\n",
    "        #       we use the predicted boxes instead.\n",
    "        # boxes = proposal_boxes[0].tensor    \n",
    "        \n",
    "        # NMS\n",
    "        for nms_thresh in np.arange(0.5, 1.0, 0.1):\n",
    "            instances, ids = fast_rcnn_inference_single_image(\n",
    "                boxes, probs, image.shape[1:], \n",
    "                score_thresh=0.2, nms_thresh=nms_thresh, topk_per_image=NUM_OBJECTS\n",
    "            )\n",
    "            if len(ids) == NUM_OBJECTS:\n",
    "                break\n",
    "                \n",
    "        instances = detector_postprocess(instances, raw_height, raw_width)\n",
    "        roi_features = feature_pooled[ids].detach()\n",
    "        max_attr_prob = max_attr_prob[ids].detach()\n",
    "        max_attr_label = max_attr_label[ids].detach()\n",
    "        instances.attr_scores = max_attr_prob\n",
    "        instances.attr_classes = max_attr_label\n",
    "        \n",
    "        print(instances)\n",
    "        \n",
    "        return instances, roi_features\n",
    "\n",
    "#     all_features.append((instances,features))\n",
    "# instances, features = doit(all_imgs[-1])\n",
    "\n",
    "# print(instances.pred_boxes)\n",
    "# print(instances.scores)\n",
    "# print(instances.pred_classes)\n",
    "# print(instances.attr_classes)\n",
    "# print(instances.attr_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "images_path = \"/scratch/gobi1/johnchen/new_git_stuff/lxmert/data/medvqa/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_images\"\n",
    "LIMIT_EXAMPLES = 10000\n",
    "df = defaultdict(list)\n",
    "\n",
    "def process_images():\n",
    "    \n",
    "    for root,dirs,files in os.walk(images_path):\n",
    "        for i,file in enumerate(tqdm(files)):\n",
    "            if i >LIMIT_EXAMPLES:\n",
    "                break\n",
    "            im = cv2.imread(os.path.join(root,file))\n",
    "            \n",
    "            im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "\n",
    "            instances, features = doit(im_rgb)\n",
    "#             print(\"juck fupyter\")\n",
    "#             print(instances)\n",
    "#             print(vars(instances))\n",
    "#             print(instances.image_size[0])\n",
    "#             print(instances.attr_scores.shape)\n",
    "            df[\"img_id\"].append(file)\n",
    "            df[\"img_h\"].append(instances.image_size[0])\n",
    "            df[\"img_w\"].append(instances.image_size[1])\n",
    "            df[\"num_boxes\"].append(len(instances.pred_classes))\n",
    "            \n",
    "            df[\"objects_id\"].append(instances.pred_classes.cpu().numpy())\n",
    "            df[\"objects_conf\"].append( instances.scores.cpu().numpy())\n",
    "\n",
    "            df[\"attrs_id\"].append( instances.attr_classes.cpu().numpy())\n",
    "\n",
    "            df[\"attrs_scores\"].append( instances.attr_scores.cpu().numpy())\n",
    "\n",
    "            df[\"boxes\"].append( instances.pred_boxes.tensor.cpu().numpy())\n",
    "\n",
    "            df[\"features\"].append( features.cpu().numpy())\n",
    "            \n",
    "    all_features = pd.DataFrame(df)\n",
    "    all_features.to_csv(\"test_{}.csv\".format(LIMIT_EXAMPLES), )\n",
    "            \n",
    "#             all_imgs.append(im_rgb)\n",
    "#             showarray(im_rgb)\n",
    "\n",
    "process_images()\n",
    "# im = cv2.imread(\"/scratch/gobi1/johnchen/new_git_stuff/py-bottom-up-attention/data/synpic593.jpg\")\n",
    "# im_rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "# showarray(all_imgs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_id</th>\n",
       "      <th>objects_id</th>\n",
       "      <th>objects_conf</th>\n",
       "      <th>attrs_id</th>\n",
       "      <th>attrs_scores</th>\n",
       "      <th>boxes</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>synpic42968.jpg</td>\n",
       "      <td>[ 72  72  72  72  72 956 956  72 956 956 941 9...</td>\n",
       "      <td>[0.69351244 0.49890116 0.48968267 0.37984845 0...</td>\n",
       "      <td>[163 163 163 163 163  11  11 163  11  11 115  ...</td>\n",
       "      <td>[0.4452995  0.4949437  0.4695939  0.51592565 0...</td>\n",
       "      <td>[[5.0339971e+00 0.0000000e+00 7.8052393e+02 2....</td>\n",
       "      <td>[[0.0000000e+00 0.0000000e+00 0.0000000e+00 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>synpic47244.jpg</td>\n",
       "      <td>[191  53 274 274  53 274  53 274  53 274  53  ...</td>\n",
       "      <td>[0.50076324 0.40472943 0.37945783 0.36862713 0...</td>\n",
       "      <td>[11  0  0  0  0  0  0  0  7  0  7  7  0 11  0 ...</td>\n",
       "      <td>[0.3537783  0.19075967 0.2965493  0.27186775 0...</td>\n",
       "      <td>[[144.6067    248.95781   202.94795   306.4671...</td>\n",
       "      <td>[[4.9657074e-01 8.4801614e-02 1.4183599e+00 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>synpic18457.jpg</td>\n",
       "      <td>[1251 1251 1251  395  395  395  395  395  758 ...</td>\n",
       "      <td>[0.3819849  0.36146998 0.35105303 0.33720773 0...</td>\n",
       "      <td>[210 210   7 163 163 163 163 163   7 210 163 2...</td>\n",
       "      <td>[0.2025735  0.23160517 0.20085882 0.39709234 0...</td>\n",
       "      <td>[[1.92684525e+02 1.74144272e+02 3.60033844e+02...</td>\n",
       "      <td>[[0.0000000e+00 0.0000000e+00 2.2475598e-03 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>synpic26480.jpg</td>\n",
       "      <td>[ 956  623  242  623  976  956  623  956  956 ...</td>\n",
       "      <td>[0.42947546 0.422869   0.32063138 0.31490225 0...</td>\n",
       "      <td>[11 11 11 11 11 11 11 11 11 11 11  7 11 11 11 ...</td>\n",
       "      <td>[0.5459262  0.28252634 0.6158573  0.27720866 0...</td>\n",
       "      <td>[[5.80043755e+01 5.09970665e-01 1.01501337e+03...</td>\n",
       "      <td>[[3.5524480e-02 0.0000000e+00 0.0000000e+00 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>synpic55422.jpg</td>\n",
       "      <td>[ 248 1069 1069  683  907  248 1069]</td>\n",
       "      <td>[0.30651996 0.26655832 0.24919212 0.22590521 0...</td>\n",
       "      <td>[0 0 0 7 0 0 0]</td>\n",
       "      <td>[0.46289015 0.23835789 0.29643387 0.38620916 0...</td>\n",
       "      <td>[[2.8595343e+02 0.0000000e+00 5.0729361e+02 4....</td>\n",
       "      <td>[[1.8191656e-02 1.6593523e-02 0.0000000e+00 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>synpic60339.jpg</td>\n",
       "      <td>[ 60  60 715  60  72  72  72  60  72  72  60  ...</td>\n",
       "      <td>[0.5942373  0.539264   0.47682664 0.45885992 0...</td>\n",
       "      <td>[ 11  11   7 161 163 163 163 161 163 163 161 1...</td>\n",
       "      <td>[0.15446633 0.1649724  0.7775907  0.27600783 0...</td>\n",
       "      <td>[[3.85870270e+02 6.82138748e+01 8.47848267e+02...</td>\n",
       "      <td>[[1.4768969e+00 5.7344109e-02 4.2200065e-01 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>synpic16866.jpg</td>\n",
       "      <td>[117  96 274  96  96 191  96 274  96 117  96  ...</td>\n",
       "      <td>[0.45193458 0.44480965 0.39654863 0.39499548 0...</td>\n",
       "      <td>[  7  11 120   7  11  11   7   7  11 120   7  ...</td>\n",
       "      <td>[0.18166438 0.18142919 0.17640404 0.15566485 0...</td>\n",
       "      <td>[[175.58174     55.92364    413.1317     304.8...</td>\n",
       "      <td>[[1.31476998e-01 0.00000000e+00 2.15384558e-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>synpic48026.jpg</td>\n",
       "      <td>[ 117  117  117  117  117  117  117  117  117 ...</td>\n",
       "      <td>[0.48544645 0.47749144 0.47132853 0.45126337 0...</td>\n",
       "      <td>[ 11  11  11  11  11  11  11  11  11  11  11  ...</td>\n",
       "      <td>[0.19828098 0.2468157  0.21104896 0.20126459 0...</td>\n",
       "      <td>[[178.07211  102.06256  570.98004  476.37582 ]...</td>\n",
       "      <td>[[0.04437328 0.         0.         ... 0.     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>synpic27216.jpg</td>\n",
       "      <td>[1094 1094  453 1094 1094  453 1094  453  117 ...</td>\n",
       "      <td>[0.4763075  0.37306616 0.35470927 0.3113755  0...</td>\n",
       "      <td>[  7 210   7   7   7   7   7   7   7   7   7  ...</td>\n",
       "      <td>[0.14432126 0.1323388  0.20676573 0.1458718  0...</td>\n",
       "      <td>[[2.91491730e+02 2.33148074e+00 8.01851257e+02...</td>\n",
       "      <td>[[5.56907542e-02 0.00000000e+00 0.00000000e+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>synpic19566.jpg</td>\n",
       "      <td>[1469 1469   72  956  956  956   72  364  956]</td>\n",
       "      <td>[0.3117503  0.30170038 0.28295347 0.2733958  0...</td>\n",
       "      <td>[  0   0 163  11  11  11 163   7 163]</td>\n",
       "      <td>[0.46788448 0.520815   0.5117676  0.46408868 0...</td>\n",
       "      <td>[[2.1116339e+02 3.2704193e+02 5.3856030e+02 7....</td>\n",
       "      <td>[[7.8374511e-01 0.0000000e+00 8.3976555e-01 .....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           img_id  \\\n",
       "0             0  synpic42968.jpg   \n",
       "1             1  synpic47244.jpg   \n",
       "2             2  synpic18457.jpg   \n",
       "3             3  synpic26480.jpg   \n",
       "4             4  synpic55422.jpg   \n",
       "..          ...              ...   \n",
       "96           96  synpic60339.jpg   \n",
       "97           97  synpic16866.jpg   \n",
       "98           98  synpic48026.jpg   \n",
       "99           99  synpic27216.jpg   \n",
       "100         100  synpic19566.jpg   \n",
       "\n",
       "                                            objects_id  \\\n",
       "0    [ 72  72  72  72  72 956 956  72 956 956 941 9...   \n",
       "1    [191  53 274 274  53 274  53 274  53 274  53  ...   \n",
       "2    [1251 1251 1251  395  395  395  395  395  758 ...   \n",
       "3    [ 956  623  242  623  976  956  623  956  956 ...   \n",
       "4                 [ 248 1069 1069  683  907  248 1069]   \n",
       "..                                                 ...   \n",
       "96   [ 60  60 715  60  72  72  72  60  72  72  60  ...   \n",
       "97   [117  96 274  96  96 191  96 274  96 117  96  ...   \n",
       "98   [ 117  117  117  117  117  117  117  117  117 ...   \n",
       "99   [1094 1094  453 1094 1094  453 1094  453  117 ...   \n",
       "100     [1469 1469   72  956  956  956   72  364  956]   \n",
       "\n",
       "                                          objects_conf  \\\n",
       "0    [0.69351244 0.49890116 0.48968267 0.37984845 0...   \n",
       "1    [0.50076324 0.40472943 0.37945783 0.36862713 0...   \n",
       "2    [0.3819849  0.36146998 0.35105303 0.33720773 0...   \n",
       "3    [0.42947546 0.422869   0.32063138 0.31490225 0...   \n",
       "4    [0.30651996 0.26655832 0.24919212 0.22590521 0...   \n",
       "..                                                 ...   \n",
       "96   [0.5942373  0.539264   0.47682664 0.45885992 0...   \n",
       "97   [0.45193458 0.44480965 0.39654863 0.39499548 0...   \n",
       "98   [0.48544645 0.47749144 0.47132853 0.45126337 0...   \n",
       "99   [0.4763075  0.37306616 0.35470927 0.3113755  0...   \n",
       "100  [0.3117503  0.30170038 0.28295347 0.2733958  0...   \n",
       "\n",
       "                                              attrs_id  \\\n",
       "0    [163 163 163 163 163  11  11 163  11  11 115  ...   \n",
       "1    [11  0  0  0  0  0  0  0  7  0  7  7  0 11  0 ...   \n",
       "2    [210 210   7 163 163 163 163 163   7 210 163 2...   \n",
       "3    [11 11 11 11 11 11 11 11 11 11 11  7 11 11 11 ...   \n",
       "4                                      [0 0 0 7 0 0 0]   \n",
       "..                                                 ...   \n",
       "96   [ 11  11   7 161 163 163 163 161 163 163 161 1...   \n",
       "97   [  7  11 120   7  11  11   7   7  11 120   7  ...   \n",
       "98   [ 11  11  11  11  11  11  11  11  11  11  11  ...   \n",
       "99   [  7 210   7   7   7   7   7   7   7   7   7  ...   \n",
       "100              [  0   0 163  11  11  11 163   7 163]   \n",
       "\n",
       "                                          attrs_scores  \\\n",
       "0    [0.4452995  0.4949437  0.4695939  0.51592565 0...   \n",
       "1    [0.3537783  0.19075967 0.2965493  0.27186775 0...   \n",
       "2    [0.2025735  0.23160517 0.20085882 0.39709234 0...   \n",
       "3    [0.5459262  0.28252634 0.6158573  0.27720866 0...   \n",
       "4    [0.46289015 0.23835789 0.29643387 0.38620916 0...   \n",
       "..                                                 ...   \n",
       "96   [0.15446633 0.1649724  0.7775907  0.27600783 0...   \n",
       "97   [0.18166438 0.18142919 0.17640404 0.15566485 0...   \n",
       "98   [0.19828098 0.2468157  0.21104896 0.20126459 0...   \n",
       "99   [0.14432126 0.1323388  0.20676573 0.1458718  0...   \n",
       "100  [0.46788448 0.520815   0.5117676  0.46408868 0...   \n",
       "\n",
       "                                                 boxes  \\\n",
       "0    [[5.0339971e+00 0.0000000e+00 7.8052393e+02 2....   \n",
       "1    [[144.6067    248.95781   202.94795   306.4671...   \n",
       "2    [[1.92684525e+02 1.74144272e+02 3.60033844e+02...   \n",
       "3    [[5.80043755e+01 5.09970665e-01 1.01501337e+03...   \n",
       "4    [[2.8595343e+02 0.0000000e+00 5.0729361e+02 4....   \n",
       "..                                                 ...   \n",
       "96   [[3.85870270e+02 6.82138748e+01 8.47848267e+02...   \n",
       "97   [[175.58174     55.92364    413.1317     304.8...   \n",
       "98   [[178.07211  102.06256  570.98004  476.37582 ]...   \n",
       "99   [[2.91491730e+02 2.33148074e+00 8.01851257e+02...   \n",
       "100  [[2.1116339e+02 3.2704193e+02 5.3856030e+02 7....   \n",
       "\n",
       "                                              features  \n",
       "0    [[0.0000000e+00 0.0000000e+00 0.0000000e+00 .....  \n",
       "1    [[4.9657074e-01 8.4801614e-02 1.4183599e+00 .....  \n",
       "2    [[0.0000000e+00 0.0000000e+00 2.2475598e-03 .....  \n",
       "3    [[3.5524480e-02 0.0000000e+00 0.0000000e+00 .....  \n",
       "4    [[1.8191656e-02 1.6593523e-02 0.0000000e+00 .....  \n",
       "..                                                 ...  \n",
       "96   [[1.4768969e+00 5.7344109e-02 4.2200065e-01 .....  \n",
       "97   [[1.31476998e-01 0.00000000e+00 2.15384558e-01...  \n",
       "98   [[0.04437328 0.         0.         ... 0.     ...  \n",
       "99   [[5.56907542e-02 0.00000000e+00 0.00000000e+00...  \n",
       "100  [[7.8374511e-01 0.0000000e+00 8.3976555e-01 .....  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"test_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 11,  11,   7, 163,   7,   7,   7, 163,  11, 163,   7,  11, 163,   7,\n",
       "          7,   7,   7,   7,  11,   7,   7, 163,   7,   7,  11,   7],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances.attr_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boxes(tensor([[2.2778e+02, 1.3005e+02, 5.3285e+02, 2.9880e+02],\n",
       "        [2.2738e+02, 9.9733e+01, 5.6675e+02, 2.8024e+02],\n",
       "        [4.3529e+02, 8.8691e+00, 9.5445e+02, 4.2413e+02],\n",
       "        [1.2483e+00, 1.9482e+00, 7.3195e+02, 2.4749e+02],\n",
       "        [3.8193e+02, 3.1409e+01, 8.6606e+02, 4.6317e+02],\n",
       "        [1.7067e+02, 8.4857e+01, 5.4752e+02, 2.6166e+02],\n",
       "        [4.1901e+02, 1.2294e+02, 9.0890e+02, 5.4064e+02],\n",
       "        [4.8942e-01, 1.8325e+00, 5.7993e+02, 2.2042e+02],\n",
       "        [0.0000e+00, 2.0419e+00, 4.0364e+02, 3.5917e+02],\n",
       "        [0.0000e+00, 1.1431e+00, 4.7678e+02, 2.8606e+02],\n",
       "        [2.5373e+02, 5.2835e+01, 9.7608e+02, 4.5294e+02],\n",
       "        [2.7456e+02, 1.0568e+02, 5.2482e+02, 2.8500e+02],\n",
       "        [1.0370e+02, 2.7992e+00, 8.9314e+02, 2.5076e+02],\n",
       "        [4.9485e+02, 4.4994e+01, 1.0213e+03, 4.3988e+02],\n",
       "        [3.6639e+02, 1.2751e+02, 8.2658e+02, 5.2072e+02],\n",
       "        [3.8502e+02, 4.8876e+01, 1.0240e+03, 5.1301e+02],\n",
       "        [3.2656e+02, 6.5756e+01, 8.1299e+02, 4.7967e+02],\n",
       "        [3.3938e+01, 2.8919e+00, 8.1017e+02, 3.1828e+02],\n",
       "        [1.2827e+02, 7.1459e+01, 5.9744e+02, 5.2086e+02],\n",
       "        [1.8759e+02, 3.1269e+00, 9.7788e+02, 2.8665e+02],\n",
       "        [1.9733e+02, 9.3109e+01, 9.3544e+02, 5.0239e+02],\n",
       "        [6.3731e-01, 1.4856e+00, 4.0673e+02, 2.2128e+02],\n",
       "        [5.9074e+02, 2.0430e+01, 9.4862e+02, 5.3623e+02],\n",
       "        [5.3647e+02, 6.5260e+01, 1.0013e+03, 5.2588e+02],\n",
       "        [1.5161e+02, 1.6565e+02, 6.1565e+02, 5.9319e+02],\n",
       "        [1.8949e+02, 2.5753e+01, 6.4883e+02, 3.8779e+02]], device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(instances.pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2778e+02, 1.3005e+02, 5.3285e+02, 2.9880e+02],\n",
       "        [2.2738e+02, 9.9733e+01, 5.6675e+02, 2.8024e+02],\n",
       "        [4.3529e+02, 8.8691e+00, 9.5445e+02, 4.2413e+02],\n",
       "        [1.2483e+00, 1.9482e+00, 7.3195e+02, 2.4749e+02],\n",
       "        [3.8193e+02, 3.1409e+01, 8.6606e+02, 4.6317e+02],\n",
       "        [1.7067e+02, 8.4857e+01, 5.4752e+02, 2.6166e+02],\n",
       "        [4.1901e+02, 1.2294e+02, 9.0890e+02, 5.4064e+02],\n",
       "        [4.8942e-01, 1.8325e+00, 5.7993e+02, 2.2042e+02],\n",
       "        [0.0000e+00, 2.0419e+00, 4.0364e+02, 3.5917e+02],\n",
       "        [0.0000e+00, 1.1431e+00, 4.7678e+02, 2.8606e+02],\n",
       "        [2.5373e+02, 5.2835e+01, 9.7608e+02, 4.5294e+02],\n",
       "        [2.7456e+02, 1.0568e+02, 5.2482e+02, 2.8500e+02],\n",
       "        [1.0370e+02, 2.7992e+00, 8.9314e+02, 2.5076e+02],\n",
       "        [4.9485e+02, 4.4994e+01, 1.0213e+03, 4.3988e+02],\n",
       "        [3.6639e+02, 1.2751e+02, 8.2658e+02, 5.2072e+02],\n",
       "        [3.8502e+02, 4.8876e+01, 1.0240e+03, 5.1301e+02],\n",
       "        [3.2656e+02, 6.5756e+01, 8.1299e+02, 4.7967e+02],\n",
       "        [3.3938e+01, 2.8919e+00, 8.1017e+02, 3.1828e+02],\n",
       "        [1.2827e+02, 7.1459e+01, 5.9744e+02, 5.2086e+02],\n",
       "        [1.8759e+02, 3.1269e+00, 9.7788e+02, 2.8665e+02],\n",
       "        [1.9733e+02, 9.3109e+01, 9.3544e+02, 5.0239e+02],\n",
       "        [6.3731e-01, 1.4856e+00, 4.0673e+02, 2.2128e+02],\n",
       "        [5.9074e+02, 2.0430e+01, 9.4862e+02, 5.3623e+02],\n",
       "        [5.3647e+02, 6.5260e+01, 1.0013e+03, 5.2588e+02],\n",
       "        [1.5161e+02, 1.6565e+02, 6.1565e+02, 5.9319e+02],\n",
       "        [1.8949e+02, 2.5753e+01, 6.4883e+02, 3.8779e+02]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances.pred_boxes.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances.pred_boxes.tensor.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances.attr_scores.cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objects_id</th>\n",
       "      <th>objects_conf</th>\n",
       "      <th>attrs_id</th>\n",
       "      <th>attrs_scores</th>\n",
       "      <th>boxes</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[180, 180, 758, 72, 758, 180, 758, 72, 72, 72,...</td>\n",
       "      <td>[0.55572504, 0.44533208, 0.3769128, 0.37550977...</td>\n",
       "      <td>[11, 11, 7, 163, 7, 7, 7, 163, 11, 163, 7, 11,...</td>\n",
       "      <td>[0.20495716, 0.15364008, 0.33251885, 0.2434687...</td>\n",
       "      <td>[[227.7801, 130.04909, 532.8466, 298.8005], [2...</td>\n",
       "      <td>[[0.09992137, 0.0, 0.041029725, 0.62173855, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          objects_id  \\\n",
       "0  [180, 180, 758, 72, 758, 180, 758, 72, 72, 72,...   \n",
       "\n",
       "                                        objects_conf  \\\n",
       "0  [0.55572504, 0.44533208, 0.3769128, 0.37550977...   \n",
       "\n",
       "                                            attrs_id  \\\n",
       "0  [11, 11, 7, 163, 7, 7, 7, 163, 11, 163, 7, 11,...   \n",
       "\n",
       "                                        attrs_scores  \\\n",
       "0  [0.20495716, 0.15364008, 0.33251885, 0.2434687...   \n",
       "\n",
       "                                               boxes  \\\n",
       "0  [[227.7801, 130.04909, 532.8466, 298.8005], [2...   \n",
       "\n",
       "                                            features  \n",
       "0  [[0.09992137, 0.0, 0.041029725, 0.62173855, 0....  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the boxes, labels, and features\n",
    "pred = instances.to('cpu')\n",
    "v = Visualizer(im[:, :, :], MetadataCatalog.get(\"vg\"), scale=1.2)\n",
    "v = v.draw_instance_predictions(pred)\n",
    "showarray(v.get_image()[:, :, ::-1])\n",
    "print('instances:\\n', instances)\n",
    "print()\n",
    "print('boxes:\\n', instances.pred_boxes)\n",
    "print()\n",
    "print('Shape of features:\\n', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the correspondence of RoI features\n",
    "pred_class_logits, pred_attr_logits, pred_proposal_deltas = predictor.model.roi_heads.box_predictor(features)\n",
    "pred_class_probs = torch.nn.functional.softmax(pred_class_logits, -1)[:, :-1]\n",
    "max_probs, max_classes = pred_class_probs.max(-1)\n",
    "print(\"%d objects are different, it is because the classes-aware NMS process\" % (NUM_OBJECTS - torch.eq(instances.pred_classes, max_classes).sum().item()))\n",
    "print(\"The total difference of score is %0.4f\" % (instances.scores - max_probs).abs().sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bua] *",
   "language": "python",
   "name": "conda-env-bua-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
